de.airport<-flights %>% group_by(dest) %>% summarise(mean=mean(arr_delay, na.rm=TRUE))
View(de.airport)
de.airport<-flights %>% group_by(dest) %>% summarise(mean=mean(arr_delay, na.rm=TRUE)) %>% filter(mean==max(mean))
de.airport<-flights %>% group_by(dest) %>% summarise(mean=mean(arr_delay, na.rm=TRUE)) %>% arrange(mean)
View(de.airport)
id.list<-list("J000298","M001111","C000127")
committeeInfo<-function(id){
committee.resource <- "/committees?member_ids="
committee.url<- paste0(base.url,committee.resource,id)
committee.response <- GET(committee.url)
committee.res<- fromJSON(content(committee.response,"text"))$results %>% flatten() %>% mutate(member_id=id)
return(committee.res)
}
committee.data<-bind_rows(lapply(id.list,committeeInfo))
memberInfo<-function(id){
member.resource<-"/legislators?bioguide_id="
member.url <- paste0(base.url, member.resource,id)
member.response<-GET(member.url)
member.res<-fromJSON(content(member.response,"text"))$results %>% flatten()
return(member.res)
}
member.data<-bind_rows(lapply(id.list,memberInfo))
all.data<-left_join(member.data, committee.data, by=c("bioguide_id"="member_id")) %>%
group_by(first_name,last_name) %>% summarise(count=n()) %>% arrange(count)
library(httr)
library(jsonlite)
library(dplyr)
library(knitr)
id.list<-list("J000298","M001111","C000127")
committeeInfo<-function(id){
committee.resource <- "/committees?member_ids="
committee.url<- paste0(base.url,committee.resource,id)
committee.response <- GET(committee.url)
committee.res<- fromJSON(content(committee.response,"text"))$results %>% flatten() %>% mutate(member_id=id)
return(committee.res)
}
committee.data<-bind_rows(lapply(id.list,committeeInfo))
memberInfo<-function(id){
member.resource<-"/legislators?bioguide_id="
member.url <- paste0(base.url, member.resource,id)
member.response<-GET(member.url)
member.res<-fromJSON(content(member.response,"text"))$results %>% flatten()
return(member.res)
}
member.data<-bind_rows(lapply(id.list,memberInfo))
all.data<-left_join(member.data, committee.data, by=c("bioguide_id"="member_id")) %>%
group_by(first_name,last_name) %>% summarise(count=n()) %>% arrange(count)
---
title: "index"
author: "Yuting Chiu"
date: "4/29/2017"
output: html_document
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
```{r warning=FALSE, message=FALSE}
library(httr)
library(jsonlite)
library(dplyr)
library(knitr)
```
```{r}
base.url <-"https://congress.api.sunlightfoundation.com"
resource <-"/districts/locate?zip="
zip <- "98105"
uri.full <- paste0(base.url,resource,zip)
response <- GET(uri.full)
result <- fromJSON(content(response,"text"))$results %>% flatten()
district.num<-result$district
```
The district number for zipcode `r zip` is `r district.num`
```{r}
legislator.resource <- "/legislators/locate?zip="
legislator.uri<- paste0(base.url,legislator.resource,zip)
legislator.response<-GET(legislator.uri)
legislator.res<- fromJSON(content(legislator.response,"text"))$results %>% flatten()
legislator.res<-legislator.res %>%
mutate(link=paste0("[link](",website,")")) %>%
mutate(twitter=paste0("[link](http://twitter.com/",twitter_id,")"))%>%
select(first_name,last_name,title, party, chamber, phone, link, twitter)
kable(legislator.res, col.names = c("First Name", "Last Name","Title","Party","Chamber","Phone","Website","Twitter"))
```
```{r}
id.list<-list("J000298","M001111","C000127")
committeeInfo<-function(id){
committee.resource <- "/committees?member_ids="
committee.url<- paste0(base.url,committee.resource,id)
committee.response <- GET(committee.url)
committee.res<- fromJSON(content(committee.response,"text"))$results %>% flatten() %>% mutate(member_id=id)
return(committee.res)
}
committee.data<-bind_rows(lapply(id.list,committeeInfo))
memberInfo<-function(id){
member.resource<-"/legislators?bioguide_id="
member.url <- paste0(base.url, member.resource,id)
member.response<-GET(member.url)
member.res<-fromJSON(content(member.response,"text"))$results %>% flatten()
return(member.res)
}
member.data<-bind_rows(lapply(id.list,memberInfo))
all.data<-left_join(member.data, committee.data, by=c("bioguide_id"="member_id")) %>%
group_by(first_name,last_name) %>% summarise(count=n()) %>% arrange(count)
par(mar=c(5,8,2,2))
barplot(all.data$count, horiz = TRUE,las=1,main="Committees Served on by Each Rep.",xlab="#Committess",names.arg = paste(all.data$first_name,all.data$last_name))
```
```{r}
```
View(all.data)
View(committee.data)
View(all.data)
View(legislator.res)
committee.data2<-committee.data %>% filter(subcommittee==FALSE)
View(committee.data2)
selected.committe<-committee.data2[1,]
View(selected.committe)
committee.id<-committee.data2$committee_id[1]
committee.member.resource <-"/committees?committee_id=SSAP&fields=members"
committee.member.url <- paste0(base.url,"/committees?committee_id=",committee.id,"&fields=members")
committee.member.response <- GET(committee.member.url)
body <- fromJSON(content(committee.member.response,"text"))$results$members[[1]] %>% flatten()
View(body)
chair<-body %>% filter(title=="Chair") %>% select(legislator.first_name, legislator.last_name)
chair
total.memeber<- body %>% count()
total.memeber
committee.rep<-committee.data2$member_id[1]
rep.side<-body %>% filter(legislator.bioguide_id)
rep.side<-body %>% filter(legislator.bioguide_id==committee.rep)
View(rep.side)
rep.side<-body %>% filter(legislator.bioguide_id==committee.rep) %>% select(side)
View(rep.side)
View(all.data)
gender<-body %>% group_by(legislator.gender)
View(gender)
gender<-body %>% group_by(legislator.gender) %>% summarise(count=n())
View(gender)
male.dist<-gender[legislator.gender=='M']/total.memeber
male.dist<-gender$legislator.gender='M'/total.memeber
male.dist<-gender %>% filter(legislator.gender=='M')/total.memeber
gender$count[legislator.gender]
gender$legislator.gender
gender$legislator.gender="M"
gender['M','count']
gender<-body %>% group_by(legislator.gender) %>% summarise(count=n())
gender$legislator.gender['M',count]
gender$legislator.gender['M','count']
gender['M','count']
gender[1,2]
gender[legislator.gender='M',2]
gender[legislator.gender=='M',2]
gender['M',2]
gender[gender$legislator.gender == M]
gender[gender$legislator.gender == "M"]
gender[gender$legislator.gender == "M",]
gender[gender$legislator.gender == "M",'count']
total.member<- body %>% count()
chair<-body %>% filter(title=="Chair") %>% select(legislator.first_name, legislator.last_name)
total.member<- body %>% count()
rep.side<-body %>% filter(legislator.bioguide_id==committee.rep) %>% select(side)
male.dist<- round((gender[gender$legislator.gender == "M",'count']/total.member),2)
female.dist<-round((gender[gender$legislator.gender == "F",'count']/total.member),2)
gender<- body %>% group_by(legislator.gender) %>% summarise(count=n())
#convert the gender protion to percentage
none.subcommittee.data<-committee.data %>% filter(subcommittee==FALSE)
committee.id<-none.subcommittee.data$committee_id[1]
committee.rep<-none.subcommittee.data$member_id[1]
getAPI<-function(source,var){
base.url <-"https://congress.api.sunlightfoundation.com"
url.full<-paste0(base.url,source,var)
res<-GET(url.full)
final<-fromJSON(content(res,"text"))$results %>% flatten()
return(final)
}
yo<-getAPI("/districts/locate?zip=","98105")
View(yo)
yo2<-getAPI("/legislators/locate?zip=","98105")
View(yo2)
View(legislator.res)
hello<-getAPI("/committees?member_ids=",id.list)
zip<-"98105"
district.data<-getAPI("/districts/locate?zip=",zip)
district.num<-district.data$district
district.num
base.url <-"https://congress.api.sunlightfoundation.com"
com<-function(ids){
getAPI("/committees?member_ids=",ids)
}
getAPI("/committees?member_ids=",id.list)
base.url <-"https://congress.api.sunlightfoundation.com"
#reduce the redundancy of getting APIs for many times, so write it as a function
getAPI<-function(resource,var){
url.full<-paste0(base.url,resource,var)
res<-GET(url.full)
final<-fromJSON(content(res,"text"))$results %>% flatten()
return(final)
}
View(none.subcommittee.data)
cereal<-read.csv("/Users/CindyChiu/info201/a8-building-apps-chiuyt19/data/cereal.tsv",sep="\t",stringsAsFactors = FALSE,na.strings = "-1" )
library(ggplot2)
library(plotly)
BuildScatter(cereal,"fat","calories","mfr")
p<-ggplot(cereal,aes(x=fat,y=calories,color=mfr))+geom_point(na.rm=FALSE)+geom_count()
p<-ggplotly(p)
p
BuildScatter<-function(data,scatter.x,scatter.y,scatter.color){
p<-ggplot(data,aes_string(x=scatter.x,y=scatter.y,color=scatter.color))+geom_point(na.rm=FALSE)+geom_count()
p<-ggplotly(p)
return(p)
}
BuildScatter(cereal,"fat","calories","mfr")
shiny::runApp('info201/a8-building-apps-chiuyt19')
ggplot(cereal,aes(x=fat,y=calories,color=mfr))+geom_point(na.rm=FALSE)+geom_count()+ylim(100,160)
ggplot(cereal,aes(x=fat,y=calories,color=mfr))+geom_point(na.rm=FALSE)+geom_count()+ylim(0,160)
p<-ggplotly(p)
ggplot(cereal,aes(x=fat,y=calories,color=mfr))+geom_point(na.rm=FALSE)+geom_count()+ylim(0,100)
ggplot(cereal,aes(x=fat,y=calories,color=mfr))+geom_point(na.rm=FALSE)+geom_count()+ylim(0,160)
p<-ggplotly(p)
p<-ggplot(cereal,aes(x=fat,y=calories,color=mfr))+geom_point(na.rm=FALSE)+geom_count()+ylim(0,160)
p<-ggplotly(p)
p
BuildScatter<-function(data,scatter.x,scatter.y,scatter.color,max,min){
p<-ggplot(data,aes_string(x=scatter.x,y=scatter.y,color=scatter.color))+geom_point(na.rm=FALSE)+geom_count()+ylim(min,max)
p<-ggplotly(p)
return(p)
}
BuildScatter(cereal,"fat","calories","mfr",0,120)
BuildScatter<-function(data,scatter.x,scatter.y,scatter.color,min,max){
p<-ggplot(data,aes_string(x=scatter.x,y=scatter.y,color=scatter.color))+geom_point(na.rm=FALSE)+geom_count()+ylim(min,max)
p<-ggplotly(p)
return(p)
}
BuildScatter(cereal,"fat","calories","mfr",0,120)
View(cereal)
BuildScatter<-function(data,scatter.x,scatter.y,scatter.color,max){
p<-ggplot(data,aes_string(x=scatter.x,y=scatter.y,color=scatter.color))+geom_point(na.rm=FALSE)+geom_count()+ylim(0,max)
p<-ggplotly(p)
return(p)
}
BuildScatter(cereal,"fat","calories","mfr",120)
runApp('info201/a8-building-apps-chiuyt19')
runApp('info201/a8-building-apps-chiuyt19')
runApp('info201/a8-building-apps-chiuyt19')
input$slider
install.packages('rsconnect')
install.packages("rsconnect")
install.packages("rsconnect")
install.packages('rsconnect')
install.packages("dplyr")
install.packages("plotly")
install.packages("ggplot2")
install.packages("shiny")
library(jsonlite)
library(httr)
install.packages("janeaustenr")
install.packages("tidytext")
library(janeaustenr)
library(tidytext)
library(dplyr)
library(stringr)
library(ggplot2)
austen_books()
books<-austen_books()
View(books)
books %>% group_by(book) %>% summarise(count=n())
num.book<-books %>% group_by(book) %>% summarise(count=n())
View(num.book)
nrow(num.book)
most.line.book<-num.book %>% filter(count==max(count))
most.line.book
unnest_tokens(books)
unnest_tokens(books$text)
unnest_tokens(text)
unnest_tokens()
?unnest_tokens
unnest_tokens(books,words,text)
update<-unnest_tokens(books,words,text)
View(update)
most.common<-update %>% filter(words=max(words))
most.common<-update %>% filter(words==max(words))
most.common
most.common<-update %>% group_by(words) %>% filter(words==max(words))
most.common
most.common<-update %>% group_by(words) %>% summarise(count=n()) %>% filter(count==max(count))
most.common
View(stop_words)
?anti_join
no.stop<-anti_join(update,stop_words,by=c("words","word"))
no.stop<-anti_join(update,stop_words,by=c(words,word))
no.stop<-anti_join(update,stop_words,words,word))
no.stop<-anti_join(update,stop_words,words,word)
no.stop<-anti_join(update,stop_words,by=c("words"="word"))
View(no.stop)
most.common<-update %>% group_by(words) %>% summarise(count=n())
View(most.common)
most.common<-update %>% group_by(words) %>% summarise(count=n()) %>% filter(count==max(count))
View(most.common)
no.stop %>% group_by(words) %>% summarise(count=n()) %>% filter(count==max(count))
?geom_bar
ggplot(no.stop)+geom_bar(mapping=aes(x=words))
install.packages(rvest)
install.packages('rvest')
library(tidytext)
library(dplyr)
library(stringr)
library(ggplot2)
web<-read_html("https://www.washington.edu/students/crscat/info.html")
library(rvest)
web<-read_html("https://www.washington.edu/students/crscat/info.html")
title<-web %>% html_node('p b') %>% html_text()
des<-web %>% html_node('p') %>% html_text()
titles<-web %>% html_node('p b') %>% html_text()
classes <- data.frame(title = titles, description = des[2:length(des)], stringsAsFactors = FALSE)
View(classes)
# Extract descriptions of each course into a dataframe (may take multiple steps)
titles<-web %>% html_nodes('p b') %>% html_text()
des<-web %>% html_nodes('p') %>% html_text()
classes <- data.frame(title = titles, description = des[2:length(des)], stringsAsFactors = FALSE)
View(classes)
nrow(classes)
class.words<-unnest_tokens(classes,words,description)
View(class.words)
shiny::runApp('info201/project-test')
runApp('info201/project-test')
runApp('info201/project-ae4')
library(jsonlite)
runApp('info201/project-test')
runApp('info201/project-ae4')
shiny::runApp('info201/project-test')
runApp('info201/project-test')
runApp('info201/project-test')
runApp('info201/project-test')
runApp('info201/project-test')
runApp('info201/project-test')
runApp('info201/project-ae4')
library(dplyr)
library(httr)
library(jsonlite)
# Returns the token needed to access the API
# Used to create HeaderValue
# Ex.) HeaderValue = paste0('Bearer ', GetSpotifyToken())
GetToken <- function(){
clientID = 'ba7340b971c049a595b54cb4af1b266d'
secret = '2e9fe1e67aae46fd8f9fd0e981edebde'
response <- POST('https://accounts.spotify.com/api/token',
accept_json(),
authenticate(clientID, secret),
body=list(grant_type='client_credentials'),
encode='form',
verbose())
return(content(response)$access_token)
}
# artistName <- String with name of artist. Ex.)"Drake"
# RETURNS: Artist object with info about artist
GetArtist <- function(artistName) {
HeaderValue = paste0('Bearer ', GetToken())
URI = paste0('https://api.spotify.com/v1/search?query=', artistName,'&offset=0&limit=20&type=artist')
response = GET(url = URI, add_headers(Authorization = HeaderValue))
body<-content(response)
info<-body$artists$items
#turn a bunch of lists into dataframe which we can access data from
my.matrix<-do.call("rbind",info)
my.df<-as.data.frame(my.matrix, stringsAsFactors=FALSE)
#the values are list,turn column that we're interested into numeric/character so we can filter
my.df$popularity<-as.numeric(my.df$popularity)
my.df$name<-as.character(my.df$name)
my.df$id<-as.character(my.df$id)
#return the most popular artist (since there are too many artists with same name)
#my.df<-my.df %>% filter(popularity==max(popularity))
return(my.df)
}
GetArtist("Katy%Perry")
library(dplyr)
GetArtist("Katy%Perry")
GetArtist("Katy%20Perry")
yo<-GetArtist("katy%20Perry")
View(yo)
GetArtist("KatyZ%20Perry")
View(yo)
setwd("~/Research/nexis-uni")
library(dplyr)
library(httr)
library(jsonlite)
basic.url <-"http://advance.lexis.com/api/"
base.url <-"http://advance.lexis.com/api/"
query.params<-
base.url <-"http://advance.lexis.com/api/search?"
search.term <- "UrWork"
query.params<- paste0("q=", search.term)
url.full <- paste0(base.url, query.params,"&collection=cases&qlang=bool&context=1516831")
response <- GET(url.full)
response
chiuyt19
response2 <- POST(url.full)
base.url <-"http://advance.lexis.com/api/search?"
#Chinese unicorn firm with 256 news article in the GUI search
search.term <- "UrWork"
#for terms with spaces, add "%20" to replace in the search
query.params<- paste0("q=", search.term)
url.full <- paste0(base.url, query.params,"&collection=cases&qlang=bool&context=1516831")
#http://advance.lexis.com/api/search?{search-terms}&{collection}&{qlang}&(context)
#eg. http://advance.lexis.com/api/search?q=burden%20of%20proof&collection=cases&qlang=bool&context=1516831
#qlang = language optional collection = content type optional
response <- GET(url.full)
install.packages("plumber")
install.packages("RCurl")
response["url"]
library(RCurl)
?list
pars=list(username="chiuyt19",password="Chiu27905639@")
?curlSetOpt
loginurl = "https://signin.lexisnexis.com/lnaccess/app/signin?back=https%3A%2F%2Fadvance.lexis.com%3A443%2Fnexis-uni%2Flaapi%2Fsearch%3Fq%3DUrWork%26collection%3Dcases%26qlang%3Dbool%26context%3D1516831&aci=nu"
pars=list(username="chiuyt19",password="Chiu27905639@")
curl=getCurlHandle()
curlSetOpt(cookiejar="cookies.txt",followlocation = TRUE, curl=curl)
html=postForm(loginurl, .params=pars, curl=curl)
html=getURL(url.full, curl=curl)
curl=getCurlHandle()
curlSetOpt(cookiejar="cookies.txt",followlocation = TRUE, curl=curl)
html=postForm(loginurl, .params=pars, curl=curl)
html=getURL(url.full, curl=curl)
matchref=gregexpr("... my regexp ...", html)
basic.url<-"http://advance.lexis.com/api/"
html=getURL(basic.url, curl=curl)
url.full <- paste0(base.url, query.params,"&collection=news&qlang=bool&context=1516831")
html=getURL(url.full, curl=curl)
html=postForm(loginurl, .params=pars, curl=curl)
html=getURL(url.full, curl=curl)
query.params<- paste0("q=", search.term)
url.full <- paste0(base.url, query.params,"&collection=news&qlang=bool&context=1516831")
response <- GET(url.full)
response['url']
loginurl = "https://signin.lexisnexis.com/lnaccess/app/signin?back=https%3A%2F%2Fadvance.lexis.com%3A443%2Fnexis-uni&aci=nu"
pars=list(username="chiuyt19",password="Chiu27905639@")
curl=getCurlHandle()
curlSetOpt(cookiejar="cookies.txt",followlocation = TRUE, curl=curl)
html=postForm(loginurl, .params=pars, curl=curl)
html=getURL(url.full, curl=curl)
matchref=gregexpr("... my regexp ...", html)
rm(curl)
cookies(response)
loginurl = "https://signin.lexisnexis.com/lnaccess/app/signin?back=https%3A%2F%2Fadvance.lexis.com%3A443%2Fnexis-uni%2Flaapi%2Fresearch%2Fhome%3Fcontext%3D1516831%26primaryipauth%3Dtrue&aci=nu"
pars=list(username="chiuyt19",password="Chiu27905639@")
curl=getCurlHandle()
curlSetOpt(cookiejar="cookies.txt",followlocation = TRUE, curl=curl)
html=postForm(loginurl, .params=pars, curl=curl)
html=getURL(url.full, curl=curl)
response <- GET(url.full)
html
pars=list(username="chiuyt19",password="Chiu27905639@",agent = "Chrome/63.0.3239.84")
html=postForm(loginurl, .params=pars, curl=curl, style="POST")
url.full <- paste0(base.url, query.params,"&collection=news&qlang=bool&context=1516831")
html=getURL(url.full, curl=curl)
html=postForm(loginurl, .params=pars, curl=curl, style="POST")
?postForm
pars=list(ID="chiuyt19",Password="Chiu27905639@",submitButton = "Sign In", agent = "Chrome/63.0.3239.84")
curl=getCurlHandle()
curlSetOpt(cookiejar="cookies.txt",followlocation = TRUE, curl=curl)
html=postForm(loginurl, .params=pars, curl=curl, style="POST")
html=getURL(url.full, curl=curl)
html
agent ="Mozilla/5.0"
loginurl = "https://signin.lexisnexis.com/lnaccess/app/signin?back=https%3A%2F%2Fadvance.lexis.com%3A443%2Fnexis-uni&aci=nu"
loginurl = "https://signin.lexisnexis.com/lnaccess/app/signin?back=https%3A%2F%2Fadvance.lexis.com%3A443%2Fnexis-uni%2Flaapi%2Fresearch%2Fhome%3Fcontext%3D1516831%26primaryipauth%3Dtrue&aci=nu"
pars=list(ID="chiuyt19",Password="Chiu27905639@",submitButton = "Sign In")
agent ="Mozilla/5.0"
curl=getCurlHandle()
curlSetOpt(cookiejar="cookies.txt",useragent= agent, followlocation = TRUE, curl=curl)
html=postForm(loginurl, .params=pars, curl=curl, style="POST")
search.term <- "UrWork"
query.params<- paste0("q=", search.term)
url.full <- paste0(base.url, query.params,"&collection=news&qlang=bool&context=1516831")
base.url <-"http://advance.lexis.com/api/search?"
url.full <- paste0(base.url, query.params,"&collection=news&qlang=bool&context=1516831")
html=getURL(url.full, curl=curl)
html
loginurl ="advance.lexis.com"
pars=list(ID="chiuyt19",Password="Chiu27905639@",submitButton = "Sign In")
agent ="Mozilla/5.0"
curl=getCurlHandle()
curlSetOpt(cookiejar="cookies.txt",useragent= agent, followlocation = TRUE, curl=curl)
html=postForm(loginurl, .params=pars, curl=curl, style="POST")
pars=list(ID="chiuyt19",Password="Chiu27905639@")
agent ="Mozilla/5.0"
curl=getCurlHandle()
curlSetOpt(cookiejar="cookies.txt",useragent= agent, followlocation = TRUE, curl=curl)
html=postForm(loginurl, .params=pars, curl=curl, style="POST")
html=getURL(url.full, curl=curl)
html
doc = htmlParse(html, asText=TRUE)
install.packages("XML")
library(XML)
doc = htmlParse(html, asText=TRUE)
doc
loginurl = "https://signin.lexisnexis.com/lnaccess/app/signin?back=https%3A%2F%2Fadvance.lexis.com%3A443%2Fnexis-uni&aci=nu"
pars=list(ID="chiuyt19",Password="Chiu27905639@")
agent ="Mozilla/5.0"
curl=getCurlHandle()
curlSetOpt(cookiejar="cookies.txt",useragent= agent, followlocation = TRUE, curl=curl)
html=postForm(loginurl, .params=pars, curl=curl, style="POST")
html=getURL(url.full, curl=curl)
doc = htmlParse(html, asText=TRUE)
doc
basic.url<-"http://advance.lexis.com/api/"
search.term <- "UrWork"
query.params<- paste0("q=", search.term)
url.full <- paste0(base.url, query.params,"&collection=news&qlang=bool&context=1516831")
response <- GET(url.full)
body<-content(response,"text")
body
body = htmlParse(html, asText=TRUE)
body
